\documentclass[letterpaper,10pt]{article}

\usepackage[margin=1in]{geometry}

\usepackage{amsthm,amssymb,amsmath}
%% H/T: https://tex.stackexchange.com/a/202168/32270
\usepackage{textcomp}
%% H/T: https://tex.stackexchange.com/a/56877/32270
\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage[usenames, dvipsnames]{color}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  urlcolor=blue,
  citecolor=ForestGreen,
  pdfinfo={
    CreationDate={D:20180425160342},
    ModDate={D:20180425160342},
  },
}

\usepackage{embedfile}
\embedfile{\jobname.tex}

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{\(K\)-compensated de Casteljau}
\rhead{Danny Hermes}

\renewcommand{\headrulewidth}{0pt}
\newcommand{\cond}[1]{\operatorname{cond}\left(#1\right)}
\newcommand{\fl}[1]{\operatorname{fl}\left(#1\right)}
\newcommand{\eps}{\varepsilon}

\begin{document}

\tableofcontents

\section{IEEE Stuff}

\begin{algorithm}[H]
  \caption{\textit{EFT of the sum of two floating point numbers.}}

  \begin{algorithmic}
    \Function{\(\left[x, y\right] = \mathtt{TwoSum}\)}{$a, b$}
      \State \(x = a \oplus b\)
      \State \(z = x \ominus a\)
      \State \(y = (a \ominus (x \ominus z)) \oplus (b \ominus z)\)
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{\textit{Splitting of a floating point number into two parts.}}

  \begin{algorithmic}
    \Function{\(\left[x, y\right] = \mathtt{Split}\)}{$a$}
      \State \(z = a \otimes (2^r + 1)\)
      \State \(x = z \ominus (z \ominus a)\)
      \State \(y = a \ominus x\)
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{\textit{EFT of the product of two floating point numbers.}}

  \begin{algorithmic}
    \Function{\(\left[x, y\right] = \mathtt{TwoProd}\)}{$a, b$}
      \State \(x = a \otimes b\)
      \State \(\left[a_h, a_l\right] = \mathtt{Split}(a)\)
      \State \(\left[b_h, b_l\right] = \mathtt{Split}(b)\)
      \State \(y = a_l \otimes b_l \ominus (((x \ominus a_h \otimes b_h)
          \ominus a_l \otimes b_h) \ominus a_h \otimes b_l)\)
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{\textit{EFT of the sum of two floating point numbers with a FMA.}}

  \begin{algorithmic}
    \Function{\(\left[x, y\right] = \mathtt{TwoProdFMA}\)}{$a, b$}
      \State \(x = a \otimes b\)
      \State \(y = \mathtt{FMA}(a, b, -x)\)
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{\textit{de Casteljau algorithm for polynomial evaluation.}}

  \begin{algorithmic}
    \Function{\(\mathtt{res} = \mathtt{DeCasteljau}\)}{$p, s$}
      \State \(n = \texttt{length}(p) - 1\)
      \State \(r = 1 \ominus s\)
      \\
      \For{\(j = 0, \ldots, n\)}
        \State \(b_j^{(n)} = p_j\)
      \EndFor
      \\
      \For{\(k = n - 1, \ldots, 0\)}
        \For{\(j = 0, \ldots, k\)}
          \State \(b_j^{(k)} = \left(r \otimes b_j^{(k + 1)}\right) \oplus
              \left(s \otimes b_{j + 1}^{(k + 1)}\right)\)
        \EndFor
      \EndFor
      \\
      \State \(\mathtt{res} = b_0^{(0)}\)
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{\textit{Compensated de Casteljau algorithm for polynomial evaluation.}}

  \begin{algorithmic}
    \Function{\(\mathtt{res} = \mathtt{CompDeCasteljau}\)}{$p, s$}
      \State \(n = \texttt{length}(p) - 1\)
      \State \(\left[r, \rho\right] = \mathtt{TwoSum}(1, -s)\)
      \\
      \For{\(j = 0, \ldots, n\)}
        \State \(b_j^{(n)} = p_j\)
        \State \(e_j^{(n)} = 0\)
      \EndFor
      \\
      \For{\(k = n - 1, \ldots, 0\)}
        \For{\(j = 0, \ldots, k\)}
          \State \(\left[P_1, \pi_1\right] = \mathtt{TwoProd}\left(
              r, b_j^{(k + 1)}\right)\)
          \State \(\left[P_2, \pi_2\right] = \mathtt{TwoProd}\left(
              s, b_{j + 1}^{(k + 1)}\right)\)
          \State \(\left[b_j^{(k)}, \sigma_3\right] = \mathtt{TwoSum}(
              P_1, P_2)\)
          \State \(w = \pi_1 \oplus \pi_2 \oplus \sigma_3 \oplus
              \left(\rho \otimes b_j^{(k + 1)}\right)\)
          \State \(e_j^{(k)} = w \oplus \left(s \otimes e_{j + 1}^{(k + 1)}
              \right) \oplus \left(r \otimes e_j^{(k + 1)}\right)\)
        \EndFor
      \EndFor
      \\
      \State \(\mathtt{res} = b_0^{(0)} \oplus e_0^{(0)}\)
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\section{de Casteljau's Method}

Consider de Casteljau's method to evaluate a degree \(n\)
polynomial in Bernstein-B\'{e}zier form with control points \(p_j\):
\begin{align*}
    b_j^{(0)} &= p_j \\
    b_j^{(k)} &= (1 - s) b_j^{(k - 1)} + s b_{j + 1}^{(k - 1)} \\
    b(s) &= b_0^{(n)}.
\end{align*}

\subsection{Condition Number}

For a polynomial \(p(x)\) in the power basis, we have
(\cite{langlois_et_al:DSP:2006:442}):
\[\cond{p(x)} = \frac{\widetilde{p}\left(\left|x\right|\right)}{
  \left|p(x)\right|} = \frac{\sum_j \left|a_j\right| \left|x\right|^j}{
  \left|p(x)\right|}.\]
In particular, this means that if \(x \geq 0\) and each \(a_j \geq 0\)
we must necessarily have \(\cond{p(x)} = 1\). To see an example in use,
consider \(p(x) = (x - 1)^n\) and input values of the form \(x = 1 + \delta\)
(with \(\left|\delta\right| \ll 1\)). Since \(a_j = \binom{n}{j} (-1)^{n - j}\)
we have \(\widetilde{p}(x) = (x + 1)^n\) hence
\[\cond{p\left(1 + \delta\right)} = \frac{(2 + \delta)^n}{
  \left|\delta\right|^n} = \left|1 + \frac{2}{\delta}\right|^n.\]
As \(\delta \to 0\), this value approaches \(\infty\) (as expected).

For a polynomial \(p(s)\) in Bernstein form, we have (\cite{Jiang2010}):
\[\cond{p(s)} = \frac{\widetilde{p}\left(s\right)}{
  \left|p(s)\right|} = \frac{\sum_j \left|p_j\right| \left|b_{j, n}(s)\right|}{
  \left|p(s)\right|}.\]
The Bernstein form is suited for \(s \in \left[0, 1\right]\), which means
\(b_{j, n}(s) \geq 0\) typically. If \(s \in \left[0, 1\right]\) and each
\(p_j \geq 0\) we must necessarily have \(\cond{p(s)} = 1\). To see an
example in use, consider
\[p(s) = (1 - 2s)^n = \left[(1 - s) - s\right]^n = \sum_j \binom{n}{j}
(1 - s)^{n - j} (-s)^j = \sum_j (-1)^j b_{j, n}(s)\]
and input values of the form \(x = \frac{1}{2} + \delta\)
(with \(\left|\delta\right| \ll \frac{1}{2}\)). Since \(p_j = (-1)^j\)
we have \(\widetilde{p}(s) = \left[(1 - s) + s\right]^n = 1\)
\[\cond{p\left(\frac{1}{2} + \delta\right)} = \frac{1}{
  \left|2\delta\right|^n}.\]
As \(\delta \to 0\), this value approaches \(\infty\) (as expected).

\subsection{Selection of Test Cases}

From \cite{Delgado2015} (end of Section 3):

\begin{quote}
  We can observe that, in this case, the algorithm with a good
  behavior everywhere is the de Casteljau algorithm
\end{quote}

\noindent In the same paper (when referring to \cite{Bezerra2013} at the
beginning of Section 2):

\begin{quote}
  assuming that all control points are positive. This assumption avoided
  ill-conditioned polynomials. In this section, we shall show that this is
  a natural assumption in Computer Aided Geometric Design (from now on,
  C.A.G.D.) and that it permits to assure high relative precision for the
  evaluation through a large family of representations in C.A.G.D.
\end{quote}

\noindent From the same author, in \cite{Mainar2005} (towards the
end of Section 5, at the bottom of page 109):

\begin{quote}
  Let us observe that in this case, the de Casteljau algorithm presents
  better stability properties for the evaluation near the roots. In fact,
  the de Casteljau algorithm has good behaviour even when using simple
  precision, although the running error bound is not so accurate in points
  close to the roots.
\end{quote}

\subsection{\texorpdfstring{\(K\)}{K}-Fold Error Filtering}

After implementing for \(K = 2, 3, \ldots, 12\) and instrumenting all
relevant floating point operations, the \(K\)-fold Horner requires
\[(5 \cdot 2^K - 8)n + \left((K + 8) 2^K - 12K - 6\right) =
\mathcal{O}\left((n + K)2^K\right)\]
flops to evaluate a degree \(n\) polynomial (this only applies when
\(n \geq K - 1\)). As a comparison, the
non-compensated form of Horner requires \(2n\) flops. Of these,
\(\left(2^{K - 1} - 1\right)n - 2^{K - 1}(K - 3) - 2\) are
FMA (fused-multiply-add) instructions.

After implementing for \(K = 2, 3, 4, 5\) and instrumenting all relevant
floating point operations, the \(K\)-fold de Casteljau requires
\[(15K^2 - 34K + 26)T_n + K + 5 =
\mathcal{O}\left(n^2 K^2\right)\]
flops to evaluate a degree \(n\) polynomial. (Here \(T_n\) is the
\(n\)th triangular number.) As a comparison, the non-compensated form of
de Casteljau requires \(3 T_n + 1\) flops. Of these, \((3K - 4)T_n\) are
FMA instructions. On hardware that doesn't support FMA,
every FMA will be exchanged for 10 \(\ominus\)'s and 6 \(\otimes\)'s so the
count will increase by \((10 + 6 - 1)(3K - 4)T_n\).

\section{Bogus Section for Refs}

Here they are, for now
\begin{itemize}
  \item Compensated Horner (\(K = 2\)) (\cite{langlois_et_al:DSP:2006:442})
  \item Compensated de Casteljau (\cite{Jiang2010})
  \item Newton with compensated Horner (\cite{Graillat2008})
  \item \(K\)-fold Sum (\cite{Ogita2005})
  \item \(K\)-fold Horner (\cite{Graillat2009})
\end{itemize}

\bibliography{paper}
\bibliographystyle{alpha}

\end{document}
